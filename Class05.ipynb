{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF8ymhuxHqr+/oZxp92Loa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/CybersecurityProblemSolvingWithDataScience/blob/main/Class05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Threat Modeling**\n",
        "Threat modeling is a continuous and essential information security practice that helps organizations identify, analyze, and mitigate risks to systems, applications, and data. It relies on high-quality data preparation, careful selection of relevant variables, and collaboration across disciplines to focus on meaningful threats. By applying appropriate modeling techniques, regularly evaluating results, and integrating data science and machine learning, organizations can proactively detect emerging threats, optimize security resources, and embed security throughout the software development lifecycle, while still relying on human expertise and organizational security awareness."
      ],
      "metadata": {
        "id": "p28-8z1wEgLe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UX8GFJNWEfQG"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Threat Modeling example**\n",
        "The example below shows how Python could be used to support threat modeling by identifying anomalies in security log data using a machine learning approach."
      ],
      "metadata": {
        "id": "jIA5AJDzFW57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example security log data:\n",
        "data = {\n",
        "    'failed_logins': [2, 3, 1, 50, 2, 3],\n",
        "    'data_transfer_mb': [10, 12, 9, 500, 11, 10]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Training an anomaly detection model:\n",
        "model = IsolationForest(contamination=0.1, random_state=42)\n",
        "df['anomaly'] = model.fit_predict(df)\n",
        "\n",
        "# Marking suspicious events:\n",
        "df['anomaly'] = df['anomaly'].map({1: 'Normal', -1: 'Potential Threat'})\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIXZcUHWFUtH",
        "outputId": "8e4760ca-3ee8-424e-c629-7f411c2f15cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   failed_logins  data_transfer_mb           anomaly\n",
            "0              2                10            Normal\n",
            "1              3                12            Normal\n",
            "2              1                 9            Normal\n",
            "3             50               500  Potential Threat\n",
            "4              2                11            Normal\n",
            "5              3                10            Normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Threat Risk Scoring**\n",
        "The example below shows risk scoring, which is a common task in threat modeling. It combines the likelihood and impact of threats to help prioritize security actions."
      ],
      "metadata": {
        "id": "iQRgxuyJF0vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example threat data:\n",
        "data = {\n",
        "    'threat': [\n",
        "        'SQL Injection',\n",
        "        'Phishing Attack',\n",
        "        'Malware Infection',\n",
        "        'Insider Threat'\n",
        "    ],\n",
        "    'likelihood': [4, 5, 3, 2], # Scale: 1 (low) to 5 (high)\n",
        "    'impact': [5, 4, 4, 5] # Scale: 1 (low) to 5 (high)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating risk score:\n",
        "df['risk_score'] = df['likelihood'] * df['impact']\n",
        "\n",
        "# Classifying the risk level:\n",
        "def classify_risk(score):\n",
        "    if score >= 20:\n",
        "        return 'Critical'\n",
        "    elif score >= 12:\n",
        "        return 'High'\n",
        "    elif score >= 6:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "df['risk_level'] = df['risk_score'].apply(classify_risk)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAwfb6MYGCoj",
        "outputId": "98c50a63-cd80-401b-e1fc-b32896893683"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              threat  likelihood  impact  risk_score risk_level\n",
            "0      SQL Injection           4       5          20   Critical\n",
            "1    Phishing Attack           5       4          20   Critical\n",
            "2  Malware Infection           3       4          12       High\n",
            "3     Insider Threat           2       5          10     Medium\n"
          ]
        }
      ]
    }
  ]
}